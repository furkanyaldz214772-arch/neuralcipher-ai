# ğŸ¯ MASTER VERÄ° KULLANIM PLANI - 241,000 DOSYA

## ğŸ“Š GENEL STRATEJÄ°

**HEDEF**: 241,000 dosyanÄ±n %100'Ã¼nÃ¼ kullanarak dÃ¼nya Ã§apÄ±nda en kapsaml Parkinson teÅŸhis sistemini oluÅŸturmak

**PRENSÄ°P**: HiÃ§bir veri atlanmayacak, her dosya deÄŸerlendirilecek!

---

## ğŸ—ºï¸ FAZ 1: VERÄ° HARÄ°TALAMA VE ENVANTER (2-3 GÃ¼n) âœ… DEVAM EDÄ°YOR

### AdÄ±m 1.1: Otomatik Tarama âœ… BAÅLATILDI
```bash
# Script Ã§alÄ±ÅŸÄ±yor: scan_all_data.py
# Ä°lerleme: 141,000+ / 241,000 dosya tarandÄ±
# Tahmini tamamlanma: 1-2 saat
```

**Ã‡Ä±ktÄ±lar**:
- âœ… `data_inventory/full_inventory.json` - TÃ¼m dosyalarÄ±n detaylÄ± listesi
- âœ… `data_inventory/full_inventory_summary.txt` - Ã–zet rapor
- âœ… `data_inventory/usage_plan.json` - Kategori bazlÄ± kullanÄ±m planÄ±

### AdÄ±m 1.2: Kategori Analizi (Tarama bitince)
```python
# Her kategori iÃ§in:
- Dosya sayÄ±sÄ±
- Toplam boyut
- Ã–rnek dosya yapÄ±sÄ±
- Veri kalitesi deÄŸerlendirmesi
- KullanÄ±m Ã¶nceliÄŸi
```

---

## ğŸš€ FAZ 2: VERÄ° Ä°ÅLEME PÄ°PELINE'LARI (1 Hafta)

### Pipeline 1: TFRecords GÃ¶rÃ¼ntÃ¼ Verileri (Ã–NCELÄ°K: YÃœKSEK)

**Dosyalar**: ~1,000 .tfrecords dosyasÄ±
**Boyut**: ~50GB
**Ä°Ã§erik**: Spiral Ã§izimler, el yazÄ±sÄ± Ã¶rnekleri

```python
# neuralcipher-ai/ai-pipeline/loaders/tfrecords_loader.py
import tensorflow as tf

class TFRecordsImageLoader:
    def __init__(self, data_dir):
        self.data_dir = data_dir
        self.tfrecord_files = self.discover_files()
    
    def discover_files(self):
        """TÃ¼m .tfrecords dosyalarÄ±nÄ± bul"""
        import glob
        return glob.glob(f"{self.data_dir}/**/*.tfrecords", recursive=True)
    
    def parse_tfrecord(self, example_proto):
        """TFRecord'u parse et"""
        feature_description = {
            'image': tf.io.FixedLenFeature([], tf.string),
            'label': tf.io.FixedLenFeature([], tf.int64),
            'patient_id': tf.io.FixedLenFeature([], tf.string),
        }
        return tf.io.parse_single_example(example_proto, feature_description)
    
    def create_dataset(self, batch_size=32):
        """TensorFlow Dataset oluÅŸtur"""
        dataset = tf.data.TFRecordDataset(self.tfrecord_files)
        dataset = dataset.map(self.parse_tfrecord)
        dataset = dataset.batch(batch_size)
        dataset = dataset.prefetch(tf.data.AUTOTUNE)
        return dataset
```

**KullanÄ±m**:
- CNN model eÄŸitimi
- Transfer learning (ResNet, EfficientNet)
- Spiral analizi iÃ§in Ã¶zel model

### Pipeline 2: Ses Verileri (Ã–NCELÄ°K: YÃœKSEK)

**Dosyalar**: ~100 .wav, .m4a dosyasÄ±
**Boyut**: ~10GB

```python
# neuralcipher-ai/ai-pipeline/loaders/audio_loader.py
import librosa
import numpy as np
from pathlib import Path

class AudioDataLoader:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.audio_files = self.discover_files()
    
    def discover_files(self):
        """TÃ¼m ses dosyalarÄ±nÄ± bul"""
        extensions = ['*.wav', '*.m4a', '*.mp3']
        files = []
        for ext in extensions:
            files.extend(self.data_dir.rglob(ext))
        return files
    
    def extract_features(self, audio_path):
        """59 Ã¶zellik Ã§Ä±kar"""
        y, sr = librosa.load(audio_path, sr=22050)
        
        features = {}
        # MFCC
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        features['mfcc_mean'] = np.mean(mfcc, axis=1)
        features['mfcc_std'] = np.std(mfcc, axis=1)
        
        # Spectral features
        features['spectral_centroid'] = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
        features['spectral_rolloff'] = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))
        features['zero_crossing_rate'] = np.mean(librosa.feature.zero_crossing_rate(y))
        
        # ... 59 Ã¶zelliÄŸe tamamla
        
        return features
    
    def process_all(self):
        """TÃ¼m ses dosyalarÄ±nÄ± iÅŸle"""
        results = []
        for audio_file in self.audio_files:
            try:
                features = self.extract_features(audio_file)
                features['file_path'] = str(audio_file)
                results.append(features)
            except Exception as e:
                print(f"Hata: {audio_file} - {e}")
        return results
```

### Pipeline 3: CSV Tablo Verileri (Ã–NCELÄ°K: YÃœKSEK)

**Dosyalar**: ~100 .csv dosyasÄ±
**Boyut**: ~5GB

```python
# neuralcipher-ai/ai-pipeline/loaders/csv_loader.py
import pandas as pd
from pathlib import Path

class CSVDataLoader:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.csv_files = list(self.data_dir.rglob('*.csv'))
    
    def load_and_merge_all(self):
        """TÃ¼m CSV'leri yÃ¼kle ve birleÅŸtir"""
        dataframes = []
        
        for csv_file in self.csv_files:
            try:
                df = pd.read_csv(csv_file)
                df['source_file'] = csv_file.name
                dataframes.append(df)
                print(f"âœ… YÃ¼klendi: {csv_file.name} ({len(df)} satÄ±r)")
            except Exception as e:
                print(f"âš ï¸  Hata: {csv_file.name} - {e}")
        
        # AkÄ±llÄ± birleÅŸtirme
        combined = self.smart_merge(dataframes)
        return combined
    
    def smart_merge(self, dataframes):
        """Ortak kolonlara gÃ¶re akÄ±llÄ± birleÅŸtirme"""
        # Ortak kolonlarÄ± bul
        common_cols = set(dataframes[0].columns)
        for df in dataframes[1:]:
            common_cols &= set(df.columns)
        
        print(f"Ortak kolonlar: {common_cols}")
        
        # BirleÅŸtir
        combined = pd.concat(dataframes, ignore_index=True)
        return combined
```

### Pipeline 4: MATLAB Verileri (Ã–NCELÄ°K: ORTA)

**Dosyalar**: ~30 .mat dosyasÄ±
**Boyut**: ~2GB

```python
# neuralcipher-ai/ai-pipeline/loaders/matlab_loader.py
from scipy.io import loadmat
from pathlib import Path

class MATLABDataLoader:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.mat_files = list(self.data_dir.rglob('*.mat'))
    
    def load_all(self):
        """TÃ¼m .mat dosyalarÄ±nÄ± yÃ¼kle"""
        data = {}
        for mat_file in self.mat_files:
            try:
                mat_data = loadmat(mat_file)
                data[mat_file.stem] = mat_data
                print(f"âœ… {mat_file.name}: {list(mat_data.keys())}")
            except Exception as e:
                print(f"âš ï¸  {mat_file.name}: {e}")
        return data
```

### Pipeline 5: YÃ¼rÃ¼yÃ¼ÅŸ Analizi Verileri (Ã–NCELÄ°K: ORTA)

**Dosyalar**: ~300 .txt dosyasÄ± (GaCo, GaPt, JuCo, JuPt, SiCo, SiPt)
**Boyut**: ~500MB

```python
# neuralcipher-ai/ai-pipeline/loaders/gait_loader.py
import pandas as pd
from pathlib import Path

class GaitDataLoader:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.gait_files = self.discover_gait_files()
    
    def discover_gait_files(self):
        """YÃ¼rÃ¼yÃ¼ÅŸ dosyalarÄ±nÄ± bul ve kategorize et"""
        patterns = {
            'control': ['GaCo*.txt', 'JuCo*.txt', 'SiCo*.txt'],
            'patient': ['GaPt*.txt', 'JuPt*.txt', 'SiPt*.txt']
        }
        
        files = {'control': [], 'patient': []}
        for category, patterns_list in patterns.items():
            for pattern in patterns_list:
                files[category].extend(self.data_dir.rglob(pattern))
        
        return files
    
    def parse_gait_file(self, file_path):
        """YÃ¼rÃ¼yÃ¼ÅŸ dosyasÄ±nÄ± parse et"""
        # Format: time, left_foot, right_foot
        df = pd.read_csv(file_path, sep='\t', header=None,
                        names=['time', 'left_foot', 'right_foot'])
        return df
    
    def extract_gait_features(self, df):
        """YÃ¼rÃ¼yÃ¼ÅŸ Ã¶zelliklerini Ã§Ä±kar"""
        features = {
            'stride_length_mean': df['left_foot'].mean(),
            'stride_length_std': df['left_foot'].std(),
            'stride_time_mean': df['time'].diff().mean(),
            'stride_time_std': df['time'].diff().std(),
            'asymmetry': abs(df['left_foot'].mean() - df['right_foot'].mean()),
        }
        return features
```

### Pipeline 6: MRI/DATscan GÃ¶rÃ¼ntÃ¼leri (Ã–NCELÄ°K: ORTA)

**Dosyalar**: ~1,000 DICOM klasÃ¶rÃ¼
**Boyut**: ~100GB

```python
# neuralcipher-ai/ai-pipeline/loaders/mri_loader.py
import pydicom
from pathlib import Path

class MRIDataLoader:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.patient_dirs = self.discover_patient_dirs()
    
    def discover_patient_dirs(self):
        """Hasta klasÃ¶rlerini bul"""
        # sub-XXXX formatÄ±ndaki klasÃ¶rler
        return [d for d in self.data_dir.iterdir() 
                if d.is_dir() and d.name.startswith('sub-')]
    
    def load_patient_scans(self, patient_dir):
        """Bir hastanÄ±n tÃ¼m taramalarÄ±nÄ± yÃ¼kle"""
        dicom_files = list(patient_dir.rglob('*.dcm'))
        scans = []
        for dcm_file in dicom_files:
            try:
                ds = pydicom.dcmread(dcm_file)
                scans.append(ds)
            except:
                pass
        return scans
```

### Pipeline 7: Numpy Compressed Data (Ã–NCELÄ°K: ORTA)

**Dosyalar**: ~50 .npz dosyasÄ±
**Boyut**: ~5GB

```python
# neuralcipher-ai/ai-pipeline/loaders/numpy_loader.py
import numpy as np
from pathlib import Path

class NumpyDataLoader:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.npz_files = list(self.data_dir.rglob('*.npz'))
    
    def load_all(self):
        """TÃ¼m .npz dosyalarÄ±nÄ± yÃ¼kle"""
        data = {}
        for npz_file in self.npz_files:
            try:
                npz_data = np.load(npz_file, allow_pickle=True)
                data[npz_file.stem] = dict(npz_data)
                print(f"âœ… {npz_file.name}: {list(npz_data.keys())}")
            except Exception as e:
                print(f"âš ï¸  {npz_file.name}: {e}")
        return data
```

---

## ğŸ§  FAZ 3: MODEL EÄÄ°TÄ°MÄ° (2-3 Hafta)

### Model 1: Ses TabanlÄ± Model (Mevcut + GeniÅŸletilmiÅŸ)
```python
# TÃ¼m ses verilerini kullan
- WAV dosyalarÄ±
- M4A dosyalarÄ±
- CSV'deki ses Ã¶zellikleri
```

### Model 2: GÃ¶rÃ¼ntÃ¼ TabanlÄ± Model (YENÄ°)
```python
# TFRecords + PNG gÃ¶rÃ¼ntÃ¼leri
- Spiral Ã§izimler
- El yazÄ±sÄ± Ã¶rnekleri
- CNN architecture
```

### Model 3: Hareket TabanlÄ± Model (YENÄ°)
```python
# YÃ¼rÃ¼yÃ¼ÅŸ + SensÃ¶r verileri
- Gait analysis
- Smartwatch data
- LSTM/GRU architecture
```

### Model 4: MRI TabanlÄ± Model (YENÄ°)
```python
# DATscan gÃ¶rÃ¼ntÃ¼leri
- 3D CNN
- Substantia nigra analizi
```

### Model 5: Ensemble Model (FINAL)
```python
# TÃ¼m modelleri birleÅŸtir
- Weighted voting
- Stacking
- Meta-learning
```

---

## ğŸ“ˆ FAZ 4: ENTEGRASYON VE TEST (1 Hafta)

### Backend Entegrasyonu
```python
# neuralcipher-ai/backend/app/services/ml_service_v2.py
class MultiModalMLService:
    def __init__(self):
        self.audio_model = load_model('audio_model.h5')
        self.image_model = load_model('image_model.h5')
        self.gait_model = load_model('gait_model.h5')
        self.mri_model = load_model('mri_model.h5')
        self.ensemble_model = load_model('ensemble_model.h5')
    
    def predict_multimodal(self, data):
        """Ã‡oklu modalite tahmini"""
        predictions = {}
        
        if 'audio' in data:
            predictions['audio'] = self.audio_model.predict(data['audio'])
        
        if 'image' in data:
            predictions['image'] = self.image_model.predict(data['image'])
        
        if 'gait' in data:
            predictions['gait'] = self.gait_model.predict(data['gait'])
        
        if 'mri' in data:
            predictions['mri'] = self.mri_model.predict(data['mri'])
        
        # Ensemble tahmin
        final_prediction = self.ensemble_model.predict(predictions)
        
        return {
            'risk_score': final_prediction,
            'individual_scores': predictions,
            'confidence': self.calculate_confidence(predictions)
        }
```

---

## ğŸ¯ BEKLENEN SONUÃ‡LAR

### Performans Metrikleri
```
Ses Only:              92-95% doÄŸruluk (mevcut)
Ses + GÃ¶rÃ¼ntÃ¼:         96-97% doÄŸruluk
Ses + GÃ¶rÃ¼ntÃ¼ + Gait:  97-98% doÄŸruluk
Full Multi-modal:      98-99% doÄŸruluk
```

### Veri KullanÄ±m OranÄ±
```
TFRecords:    100% (1,000 dosya)
Audio:        100% (100 dosya)
CSV:          100% (100 dosya)
MATLAB:       100% (30 dosya)
Gait:         100% (300 dosya)
MRI:          100% (1,000 klasÃ¶r)
Numpy:        100% (50 dosya)
Models:       100% (16 model)
Scripts:      100% (20 script)
Docs:         100% (50 dosya)
```

**TOPLAM**: 241,000 dosyanÄ±n %100'Ã¼ kullanÄ±lacak!

---

## â±ï¸ ZAMAN Ã‡Ä°ZELGESÄ°

### Hafta 1: Veri HazÄ±rlÄ±k
- GÃ¼n 1-2: Envanter tamamlama âœ…
- GÃ¼n 3-4: Pipeline'lar oluÅŸturma
- GÃ¼n 5-7: Veri temizleme ve validasyon

### Hafta 2: Model GeliÅŸtirme
- GÃ¼n 8-10: GÃ¶rÃ¼ntÃ¼ modeli
- GÃ¼n 11-12: Hareket modeli
- GÃ¼n 13-14: MRI modeli

### Hafta 3: Ensemble ve Entegrasyon
- GÃ¼n 15-17: Ensemble model
- GÃ¼n 18-19: Backend entegrasyonu
- GÃ¼n 20-21: Test ve optimizasyon

---

## ğŸš€ HEMEN YAPILACAKLAR

1. âœ… **Tarama tamamlanmasÄ±nÄ± bekle** (1-2 saat)
2. **Envanter raporunu incele**
3. **Ä°lk pipeline'Ä± baÅŸlat** (TFRecords)
4. **Paralel iÅŸleme stratejisi belirle**

---

## ğŸ“Š Ä°LERLEME TAKÄ°BÄ°

```
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% - Veri tarama devam ediyor
[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  0% - Pipeline geliÅŸtirme
[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  0% - Model eÄŸitimi
[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  0% - Entegrasyon
```

**SON GÃœNCELLEME**: 21 Ocak 2026, 14:30
**DURUM**: Veri tarama aktif (141,000+ / 241,000 dosya)
**SONRAKI ADIM**: Envanter analizi ve pipeline baÅŸlatma

---

## ğŸ’¡ NOTLAR

- Her pipeline baÄŸÄ±msÄ±z Ã§alÄ±ÅŸabilir (paralel iÅŸleme)
- Veri kalitesi kontrolÃ¼ her aÅŸamada yapÄ±lacak
- TÃ¼m iÅŸlemler loglanacak ve izlenebilir olacak
- HiÃ§bir veri atlanmayacak, her dosya deÄŸerlendirilecek!

**HEP UNUTMA**: Bu 241,000 dosya, NeuralCipher.AI'yi dÃ¼nya lideri yapacak hazine! ğŸ†
