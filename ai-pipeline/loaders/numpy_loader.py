"""
Numpy Data Loader
1.28 GB - 2 .npz dosyasÄ±
Sensor ve time-series verilerini yÃ¼kle
"""

import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple
import logging

logger = logging.getLogger(__name__)


class NumpyDataLoader:
    """Numpy compressed dosyalarÄ±nÄ± yÃ¼kler"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.npz_files = self.discover_files()
        logger.info(f"ğŸ”¢ {len(self.npz_files)} Numpy dosyasÄ± bulundu")
    
    def discover_files(self) -> List[Path]:
        """TÃ¼m .npz dosyalarÄ±nÄ± bul"""
        files = list(self.data_dir.rglob('*.npz'))
        return sorted(files)
    
    def load_npz(self, file_path: Path) -> Dict:
        """NPZ dosyasÄ±nÄ± yÃ¼kle"""
        try:
            data = np.load(str(file_path), allow_pickle=True)
            
            result = {
                'file_path': str(file_path),
                'file_name': file_path.name,
                'keys': list(data.keys()),
                'arrays': {}
            }
            
            # Her array'i yÃ¼kle
            for key in data.keys():
                result['arrays'][key] = data[key]
            
            logger.debug(f"âœ… YÃ¼klendi: {file_path.name} ({len(result['keys'])} array)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ YÃ¼kleme hatasÄ± {file_path.name}: {e}")
            return None
    
    def extract_timeseries_features(self, data: np.ndarray) -> Dict[str, float]:
        """Time-series verilerinden feature'larÄ± Ã§Ä±kar"""
        features = {}
        
        try:
            # Flatten if multidimensional
            if data.ndim > 1:
                data = data.flatten()
            
            # Basic statistics
            features['mean'] = np.mean(data)
            features['std'] = np.std(data)
            features['min'] = np.min(data)
            features['max'] = np.max(data)
            features['median'] = np.median(data)
            features['range'] = features['max'] - features['min']
            
            # Percentiles
            features['q25'] = np.percentile(data, 25)
            features['q75'] = np.percentile(data, 75)
            features['iqr'] = features['q75'] - features['q25']
            
            # Skewness and Kurtosis
            mean = features['mean']
            std = features['std']
            if std > 0:
                features['skewness'] = np.mean(((data - mean) / std) ** 3)
                features['kurtosis'] = np.mean(((data - mean) / std) ** 4) - 3
            else:
                features['skewness'] = 0
                features['kurtosis'] = 0
            
            # Autocorrelation
            if len(data) > 1:
                autocorr = np.correlate(data, data, mode='full')
                autocorr = autocorr[len(autocorr)//2:]
                if autocorr[0] != 0:
                    autocorr = autocorr / autocorr[0]
                    features['autocorr_lag1'] = autocorr[1] if len(autocorr) > 1 else 0
                    features['autocorr_lag5'] = autocorr[5] if len(autocorr) > 5 else 0
            
            # Trend
            if len(data) > 2:
                x = np.arange(len(data))
                coeffs = np.polyfit(x, data, 1)
                features['trend_slope'] = coeffs[0]
                features['trend_intercept'] = coeffs[1]
            
            # Zero crossing rate
            zero_crossings = np.where(np.diff(np.sign(data)))[0]
            features['zero_crossing_rate'] = len(zero_crossings) / len(data)
            
            # Energy
            features['energy'] = np.sum(data ** 2)
            features['rms'] = np.sqrt(features['energy'] / len(data))
            
        except Exception as e:
            logger.error(f"âŒ Feature extraction hatasÄ±: {e}")
        
        return features
    
    def process_all(self) -> List[Dict]:
        """TÃ¼m NPZ dosyalarÄ±nÄ± iÅŸle"""
        logger.info("ğŸ”¢ TÃ¼m Numpy dosyalarÄ± iÅŸleniyor...")
        
        results = []
        for file_path in self.npz_files:
            data_dict = self.load_npz(file_path)
            if data_dict:
                # Her array iÃ§in feature'larÄ± Ã§Ä±kar
                all_features = {}
                
                for key, array in data_dict['arrays'].items():
                    if isinstance(array, np.ndarray):
                        features = self.extract_timeseries_features(array)
                        # Key prefix ekle
                        for feat_name, feat_value in features.items():
                            all_features[f'{key}_{feat_name}'] = feat_value
                
                results.append({
                    'file_path': str(file_path),
                    'file_name': file_path.name,
                    'keys': data_dict['keys'],
                    'features': all_features
                })
        
        logger.info(f"âœ… {len(results)} Numpy dosyasÄ± iÅŸlendi")
        return results
    
    def create_feature_matrix(self, results: List[Dict]) -> Tuple[np.ndarray, np.ndarray]:
        """Feature matrix oluÅŸtur"""
        if not results:
            return None, None
        
        # TÃ¼m feature names'leri topla
        all_feature_names = set()
        for r in results:
            all_feature_names.update(r['features'].keys())
        
        feature_names = sorted(list(all_feature_names))
        
        # Matrix oluÅŸtur
        X = []
        for r in results:
            features = [r['features'].get(fn, 0) for fn in feature_names]
            X.append(features)
        
        X = np.array(X)
        
        # NaN ve Inf deÄŸerleri temizle
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        
        logger.info(f"âœ… Feature matrix: X={X.shape}")
        
        return X, feature_names


def test_loader():
    """Loader'Ä± test et"""
    print("ğŸ”¢ Numpy Loader Test")
    print("=" * 80)
    
    loader = NumpyDataLoader("../../Veriler")
    
    if loader.npz_files:
        print(f"\nğŸ”„ Ä°lk dosya test ediliyor: {loader.npz_files[0].name}")
        data_dict = loader.load_npz(loader.npz_files[0])
        
        if data_dict:
            print(f"\nâœ… Veri yÃ¼klendi:")
            print(f"  Keys: {data_dict['keys']}")
            
            for key, array in list(data_dict['arrays'].items())[:3]:
                if isinstance(array, np.ndarray):
                    print(f"\n  {key}:")
                    print(f"    Shape: {array.shape}")
                    print(f"    Dtype: {array.dtype}")
                    
                    features = loader.extract_timeseries_features(array)
                    print(f"    Features: {len(features)}")


if __name__ == "__main__":
    test_loader()
