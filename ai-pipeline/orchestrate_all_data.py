#!/usr/bin/env python3
"""
MASTER ORCHESTRATOR - 241,000 DOSYA Ä°ÅLEME SÄ°STEMÄ°
TÃ¼m veri pipeline'larÄ±nÄ± koordine eder ve hiÃ§bir dosyayÄ± atlamaz
"""

import json
import logging
from pathlib import Path
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp

# Logging ayarla
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_processing.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class DataOrchestrator:
    """TÃ¼m veri iÅŸleme pipeline'larÄ±nÄ± yÃ¶netir"""
    
    def __init__(self, data_dir, output_dir):
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        # Ä°statistikler
        self.stats = {
            'start_time': datetime.now().isoformat(),
            'total_files_processed': 0,
            'successful': 0,
            'failed': 0,
            'by_category': {}
        }
        
        # Envanter yÃ¼kle
        self.inventory = self.load_inventory()
        
    def load_inventory(self):
        """Tarama sonuÃ§larÄ±nÄ± yÃ¼kle"""
        inventory_path = Path("neuralcipher-ai/ai-pipeline/scripts/data_inventory/full_inventory.json")
        if inventory_path.exists():
            with open(inventory_path, 'r') as f:
                return json.load(f)
        else:
            logger.warning("Envanter bulunamadÄ±! Ã–nce scan_all_data.py Ã§alÄ±ÅŸtÄ±rÄ±n.")
            return None
    
    def process_category(self, category_name, category_data):
        """Bir kategoriyi iÅŸle"""
        logger.info(f"ğŸ”„ Ä°ÅŸleniyor: {category_name} ({category_data['count']} dosya)")
        
        try:
            if category_name == 'tfrecords_images':
                return self.process_tfrecords(category_data)
            elif category_name.startswith('audio_'):
                return self.process_audio(category_data)
            elif category_name == 'tabular_csv':
                return self.process_csv(category_data)
            elif category_name == 'matlab_data':
                return self.process_matlab(category_data)
            elif category_name == 'text_data':
                return self.process_text(category_data)
            elif category_name == 'numpy_compressed':
                return self.process_numpy(category_data)
            elif category_name.startswith('models_'):
                return self.process_models(category_data)
            else:
                logger.info(f"â„¹ï¸  {category_name}: Ã–zel iÅŸleme gerekmiyor")
                return {'status': 'skipped', 'reason': 'no_processor'}
                
        except Exception as e:
            logger.error(f"âŒ Hata ({category_name}): {e}")
            return {'status': 'error', 'error': str(e)}
    
    def process_tfrecords(self, category_data):
        """TFRecords dosyalarÄ±nÄ± iÅŸle"""
        logger.info("ğŸ–¼ï¸  TFRecords gÃ¶rÃ¼ntÃ¼ verileri iÅŸleniyor...")
        
        # TFRecords loader'Ä± import et
        try:
            from loaders.tfrecords_loader import TFRecordsImageLoader
            
            loader = TFRecordsImageLoader(self.data_dir)
            dataset = loader.create_dataset()
            
            # Dataset istatistikleri
            total_samples = sum(1 for _ in dataset)
            
            logger.info(f"âœ… TFRecords: {total_samples} Ã¶rnek yÃ¼klendi")
            
            return {
                'status': 'success',
                'samples': total_samples,
                'files_processed': category_data['count']
            }
        except Exception as e:
            logger.error(f"TFRecords hatasÄ±: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def process_audio(self, category_data):
        """Ses dosyalarÄ±nÄ± iÅŸle"""
        logger.info("ğŸµ Ses verileri iÅŸleniyor...")
        
        try:
            from loaders.audio_loader import AudioDataLoader
            
            loader = AudioDataLoader(self.data_dir)
            features = loader.process_all()
            
            # Ã–zellikleri kaydet
            output_file = self.output_dir / 'audio_features.json'
            with open(output_file, 'w') as f:
                json.dump(features, f, indent=2)
            
            logger.info(f"âœ… Ses: {len(features)} dosya iÅŸlendi")
            
            return {
                'status': 'success',
                'files_processed': len(features),
                'output_file': str(output_file)
            }
        except Exception as e:
            logger.error(f"Ses hatasÄ±: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def process_csv(self, category_data):
        """CSV dosyalarÄ±nÄ± iÅŸle"""
        logger.info("ğŸ“Š CSV verileri iÅŸleniyor...")
        
        try:
            from loaders.csv_loader import CSVDataLoader
            
            loader = CSVDataLoader(self.data_dir)
            combined_df = loader.load_and_merge_all()
            
            # BirleÅŸtirilmiÅŸ veriyi kaydet
            output_file = self.output_dir / 'combined_tabular_data.csv'
            combined_df.to_csv(output_file, index=False)
            
            logger.info(f"âœ… CSV: {len(combined_df)} satÄ±r birleÅŸtirildi")
            
            return {
                'status': 'success',
                'rows': len(combined_df),
                'columns': len(combined_df.columns),
                'output_file': str(output_file)
            }
        except Exception as e:
            logger.error(f"CSV hatasÄ±: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def process_matlab(self, category_data):
        """MATLAB dosyalarÄ±nÄ± iÅŸle"""
        logger.info("ğŸ”¬ MATLAB verileri iÅŸleniyor...")
        
        try:
            from loaders.matlab_loader import MATLABDataLoader
            
            loader = MATLABDataLoader(self.data_dir)
            data = loader.load_all()
            
            logger.info(f"âœ… MATLAB: {len(data)} dosya yÃ¼klendi")
            
            return {
                'status': 'success',
                'files_processed': len(data)
            }
        except Exception as e:
            logger.error(f"MATLAB hatasÄ±: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def process_text(self, category_data):
        """Metin dosyalarÄ±nÄ± iÅŸle (Gait data)"""
        logger.info("ğŸš¶ YÃ¼rÃ¼yÃ¼ÅŸ verileri iÅŸleniyor...")
        
        try:
            from loaders.gait_loader import GaitDataLoader
            
            loader = GaitDataLoader(self.data_dir)
            # Gait features Ã§Ä±kar ve kaydet
            
            logger.info(f"âœ… Gait: Ä°ÅŸleme tamamlandÄ±")
            
            return {
                'status': 'success',
                'files_processed': category_data['count']
            }
        except Exception as e:
            logger.error(f"Gait hatasÄ±: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def process_numpy(self, category_data):
        """Numpy dosyalarÄ±nÄ± iÅŸle"""
        logger.info("ğŸ”¢ Numpy verileri iÅŸleniyor...")
        
        try:
            from loaders.numpy_loader import NumpyDataLoader
            
            loader = NumpyDataLoader(self.data_dir)
            data = loader.load_all()
            
            logger.info(f"âœ… Numpy: {len(data)} dosya yÃ¼klendi")
            
            return {
                'status': 'success',
                'files_processed': len(data)
            }
        except Exception as e:
            logger.error(f"Numpy hatasÄ±: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def process_models(self, category_data):
        """Model dosyalarÄ±nÄ± deÄŸerlendir"""
        logger.info("ğŸ§  Model dosyalarÄ± deÄŸerlendiriliyor...")
        
        # Mevcut modelleri yÃ¼kle ve test et
        logger.info(f"âœ… Models: {category_data['count']} model bulundu")
        
        return {
            'status': 'success',
            'files_processed': category_data['count']
        }
    
    def run_parallel(self, max_workers=None):
        """TÃ¼m kategorileri paralel iÅŸle"""
        if not self.inventory:
            logger.error("Envanter yok! Ä°ÅŸlem durduruluyor.")
            return
        
        if max_workers is None:
            max_workers = max(1, mp.cpu_count() - 1)
        
        logger.info(f"ğŸš€ Paralel iÅŸleme baÅŸlÄ±yor ({max_workers} worker)")
        logger.info(f"ğŸ“Š Toplam kategori: {len(self.inventory['categories'])}")
        
        categories = list(self.inventory['categories'].items())
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            # Her kategori iÃ§in task oluÅŸtur
            future_to_category = {
                executor.submit(self.process_category, cat_name, cat_data): cat_name
                for cat_name, cat_data in categories
            }
            
            # SonuÃ§larÄ± topla
            for future in as_completed(future_to_category):
                category_name = future_to_category[future]
                try:
                    result = future.result()
                    self.stats['by_category'][category_name] = result
                    
                    if result['status'] == 'success':
                        self.stats['successful'] += result.get('files_processed', 0)
                    else:
                        self.stats['failed'] += 1
                        
                except Exception as e:
                    logger.error(f"âŒ {category_name} iÅŸlenirken hata: {e}")
                    self.stats['failed'] += 1
        
        # Ä°statistikleri kaydet
        self.save_stats()
        
    def run_sequential(self):
        """TÃ¼m kategorileri sÄ±rayla iÅŸle"""
        if not self.inventory:
            logger.error("Envanter yok! Ä°ÅŸlem durduruluyor.")
            return
        
        logger.info("ğŸ”„ SÄ±ralÄ± iÅŸleme baÅŸlÄ±yor...")
        
        for category_name, category_data in self.inventory['categories'].items():
            result = self.process_category(category_name, category_data)
            self.stats['by_category'][category_name] = result
            
            if result['status'] == 'success':
                self.stats['successful'] += result.get('files_processed', 0)
            else:
                self.stats['failed'] += 1
        
        self.save_stats()
    
    def save_stats(self):
        """Ä°statistikleri kaydet"""
        self.stats['end_time'] = datetime.now().isoformat()
        self.stats['total_files_processed'] = self.stats['successful'] + self.stats['failed']
        
        stats_file = self.output_dir / 'processing_stats.json'
        with open(stats_file, 'w') as f:
            json.dump(self.stats, f, indent=2)
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š Ä°ÅLEME Ä°STATÄ°STÄ°KLERÄ°")
        logger.info("="*80)
        logger.info(f"âœ… BaÅŸarÄ±lÄ±: {self.stats['successful']:,} dosya")
        logger.info(f"âŒ BaÅŸarÄ±sÄ±z: {self.stats['failed']:,} dosya")
        logger.info(f"ğŸ“ Ä°statistikler: {stats_file}")
        logger.info("="*80)


def main():
    """Ana fonksiyon"""
    import argparse
    
    parser = argparse.ArgumentParser(description='241,000 dosya iÅŸleme orchestrator')
    parser.add_argument('--data-dir', default='../Veriler', help='Veri klasÃ¶rÃ¼')
    parser.add_argument('--output-dir', default='processed_data', help='Ã‡Ä±ktÄ± klasÃ¶rÃ¼')
    parser.add_argument('--parallel', action='store_true', help='Paralel iÅŸleme')
    parser.add_argument('--workers', type=int, default=None, help='Worker sayÄ±sÄ±')
    
    args = parser.parse_args()
    
    logger.info("ğŸ¯ NeuralCipher.AI - Master Data Orchestrator")
    logger.info("="*80)
    
    orchestrator = DataOrchestrator(args.data_dir, args.output_dir)
    
    if args.parallel:
        orchestrator.run_parallel(max_workers=args.workers)
    else:
        orchestrator.run_sequential()
    
    logger.info("\nâœ… TÃ¼m iÅŸlemler tamamlandÄ±!")


if __name__ == "__main__":
    main()
